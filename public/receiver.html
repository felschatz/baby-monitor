<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <title>Baby Monitor - Receiver</title>
    <link rel="stylesheet" href="receiver.css">
</head>
<body>
    <!-- Alert overlays -->
    <div class="alert-overlay loud-alert" id="loudAlert">
        LOUD SOUND DETECTED
    </div>
    <div class="alert-overlay disconnect-alert" id="disconnectAlert">
        CONNECTION LOST
    </div>

    <div class="header">
        <a href="/" class="back-link">‚Üê</a>
        <h2>Parent's Phone</h2>
        <div class="status-indicator">
            <div class="status-dot" id="statusDot"></div>
            <span id="statusText">Connecting...</span>
        </div>
    </div>

    <div class="video-container">
        <video id="remoteVideo" autoplay playsinline muted></video>
        <div class="overlay" id="overlay">
            <p id="overlayText">Waiting for sender to start streaming...</p>
        </div>
    </div>

    <div class="ptt-container">
        <button class="ptt-btn" id="pttBtn" disabled>üé§</button>
        <div class="ptt-label" id="pttLabel">Hold to talk to baby</div>
    </div>

    <div class="music-container" id="musicContainer" style="display: none;">
        <div class="music-controls">
            <button class="music-btn" id="musicBtn">üéµ</button>
            <select class="music-timer-select" id="musicTimerSelect">
                <option value="45">45 min</option>
                <option value="60">1 hour</option>
            </select>
        </div>
        <div class="music-label" id="musicLabel">Play lullabies</div>
        <div class="music-status" id="musicStatus"></div>
    </div>

    <div class="controls">
        <div class="audio-meter">
            <div class="audio-level" id="audioLevel"></div>
            <div class="threshold-marker" id="thresholdMarker"></div>
        </div>

        <div class="info-row">
            <div class="volume-control">
                <span>üîä</span>
                <input type="range" id="volume" min="0" max="100" value="100">
                <span id="volumeValue">100%</span>
            </div>
            <button class="fullscreen-btn" id="fullscreenBtn">‚õ∂ Fullscreen</button>
        </div>

        <div class="info-row">
            <div class="sensitivity-control">
                <span>Alert sensitivity:</span>
                <input type="range" id="sensitivity" min="10" max="100" value="50">
                <span id="sensitivityValue">50</span>
            </div>
            <span id="info">Waiting...</span>
        </div>
    </div>

    <script>
        // Keep screen awake
        let wakeLock = null;

        async function requestWakeLock() {
            try {
                if ('wakeLock' in navigator) {
                    wakeLock = await navigator.wakeLock.request('screen');
                    console.log('Wake lock acquired');
                }
            } catch (err) {
                console.log('Wake lock failed:', err);
            }
        }

        document.addEventListener('visibilitychange', () => {
            if (document.visibilityState === 'visible') {
                requestWakeLock();
            }
        });

        requestWakeLock();
        
        // Track user interaction for autoplay
        let userHasInteracted = false;

        // SSE and WebRTC (no WebSockets!)
        let eventSource = null;
        let peerConnection = null;
        let audioContext = null;
        let analyser = null;
        let isConnected = false;
        let loudSoundTimeout = null;
        let loudSoundCooldown = false;
        let pendingCandidates = [];
        let receiverId = null;

        const loudAlert = document.getElementById('loudAlert');
        const disconnectAlert = document.getElementById('disconnectAlert');
        const pttBtn = document.getElementById('pttBtn');
        const pttLabel = document.getElementById('pttLabel');

        let pttStream = null;
        let pttSender = null;
        let audioStream = null;
        
        // Audio ducking - reduce baby audio while parent is talking
        const DUCKING_VOLUME = 0.15; // 15% volume during PTT
        let preDuckVolume = null;

        const remoteVideo = document.getElementById('remoteVideo');
        const statusDot = document.getElementById('statusDot');
        const statusText = document.getElementById('statusText');
        const overlay = document.getElementById('overlay');
        const overlayText = document.getElementById('overlayText');
        const audioLevel = document.getElementById('audioLevel');
        const volumeSlider = document.getElementById('volume');
        const volumeValue = document.getElementById('volumeValue');
        const sensitivitySlider = document.getElementById('sensitivity');
        const sensitivityValue = document.getElementById('sensitivityValue');
        const fullscreenBtn = document.getElementById('fullscreenBtn');
        const info = document.getElementById('info');

        // Music controls
        const musicContainer = document.getElementById('musicContainer');
        const musicBtn = document.getElementById('musicBtn');
        const musicTimerSelect = document.getElementById('musicTimerSelect');
        const musicLabel = document.getElementById('musicLabel');
        const musicStatus = document.getElementById('musicStatus');
        let musicPlaying = false;
        let musicAvailable = false;

        // Check music availability
        async function checkMusicAvailability() {
            try {
                const response = await fetch('/api/music');
                const data = await response.json();

                // Add debug timer option if enabled
                if (data.debugTimer) {
                    const debugOption = document.createElement('option');
                    debugOption.value = '1';
                    debugOption.textContent = '1 min (debug)';
                    musicTimerSelect.insertBefore(debugOption, musicTimerSelect.firstChild);
                }

                if (data.files && data.files.length > 0) {
                    musicAvailable = true;
                    musicContainer.style.display = 'block';
                    console.log('Music available:', data.files.length, 'tracks');
                } else {
                    musicContainer.style.display = 'none';
                    console.log('No music files available');
                }
            } catch (err) {
                console.error('Failed to check music availability:', err);
                musicContainer.style.display = 'none';
            }
        }

        // Toggle music playback
        function toggleMusic() {
            if (!musicAvailable) return;

            if (musicPlaying) {
                // Stop music
                sendSignal({ type: 'music-stop' });
            } else {
                // Start music
                const timerMinutes = parseInt(musicTimerSelect.value);
                sendSignal({ type: 'music-start', timerMinutes: timerMinutes });
            }
        }

        // Update music UI based on status
        function updateMusicUI() {
            if (musicPlaying) {
                musicBtn.textContent = '‚èπÔ∏è';
                musicBtn.classList.add('active');
                musicLabel.textContent = 'Stop music';
                musicTimerSelect.disabled = true;
            } else {
                musicBtn.textContent = 'üéµ';
                musicBtn.classList.remove('active');
                musicLabel.textContent = 'Play lullabies';
                musicTimerSelect.disabled = false;
                musicStatus.textContent = '';
            }
        }

        // Handle music status updates from sender
        function handleMusicStatus(message) {
            musicPlaying = message.playing;
            updateMusicUI();

            if (message.playing && message.currentTrack) {
                const mins = Math.floor(message.timerRemaining / 60);
                const secs = message.timerRemaining % 60;
                musicStatus.textContent = `‚ô™ ${message.currentTrack} ‚Ä¢ ${mins}:${secs.toString().padStart(2, '0')}`;
            }
        }

        // Music button click handler
        musicBtn.addEventListener('click', toggleMusic);

        // Check music availability on load
        checkMusicAvailability();

        // Load saved settings from localStorage
        const savedVolume = localStorage.getItem('receiver-volume');
        const savedSensitivity = localStorage.getItem('receiver-sensitivity');
        
        if (savedVolume !== null) {
            volumeSlider.value = savedVolume;
            volumeValue.textContent = savedVolume + '%';
        }
        if (savedSensitivity !== null) {
            sensitivitySlider.value = savedSensitivity;
            sensitivityValue.textContent = savedSensitivity;
        }

        // Public STUN servers (only used for IP discovery, no media passes through)
        const rtcConfig = {
            iceServers: [
                { urls: 'stun:stun.stunprotocol.org:3478' },
                { urls: 'stun:stun.nextcloud.com:443' },
                { urls: 'stun:stun.sipgate.net:3478' }
            ],
            iceCandidatePoolSize: 10
        };

        // Send signal via HTTP POST (replaces WebSocket send)
        async function sendSignal(message) {
            message.role = 'receiver';
            if (receiverId) {
                message.receiverId = receiverId;
            }
            try {
                const response = await fetch('/api/signal', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(message)
                });
                if (!response.ok) {
                    console.error('Signal failed:', response.status);
                }
            } catch (err) {
                console.error('Signal error:', err);
            }
        }

        function setConnectedState(connected) {
            isConnected = connected;
            if (connected) {
                document.body.classList.add('connected');
                statusDot.classList.add('connected');
                statusText.textContent = 'Connected';
                overlay.classList.add('hidden');
                // Hide disconnect alert when reconnected
                disconnectAlert.classList.remove('active');
                // Enable PTT
                pttBtn.disabled = false;
                // Save streaming state for auto-resume on refresh
                sessionStorage.setItem('receiver-streaming', 'true');
            } else {
                document.body.classList.remove('connected');
                statusDot.classList.remove('connected');
                statusText.textContent = 'Waiting';
                overlay.classList.remove('hidden');
                // Disable PTT
                pttBtn.disabled = true;
                stopPTT();
            }
        }

        function setDisconnectedState() {
            isConnected = false;
            document.body.classList.remove('connected');
            statusDot.classList.remove('connected');
            statusText.textContent = 'Disconnected!';
            overlay.classList.remove('hidden');
            overlayText.textContent = 'Connection lost! Reconnecting...';

            // Show disconnect alert overlay
            loudAlert.classList.remove('active');
            disconnectAlert.classList.add('active');
        }

        function triggerLoudSoundAlert() {
            if (!isConnected || loudSoundCooldown) return;

            // Show loud sound overlay
            loudAlert.classList.add('active');

            // Set cooldown to prevent constant re-triggering
            loudSoundCooldown = true;

            clearTimeout(loudSoundTimeout);
            loudSoundTimeout = setTimeout(() => {
                loudAlert.classList.remove('active');
                // Cooldown period after alert hides
                setTimeout(() => {
                    loudSoundCooldown = false;
                }, 2000); // 2 second cooldown before next alert
            }, 1000); // Show alert for 1 second
        }

        function connectSSE() {
            // Close existing connection
            if (eventSource) {
                eventSource.close();
            }

            eventSource = new EventSource('/api/sse/receiver');

            eventSource.onopen = () => {
                console.log('SSE connected');
            };

            eventSource.onmessage = async (event) => {
                const message = JSON.parse(event.data);
                if (message.type !== 'heartbeat') {
                    console.log('Receiver received:', message.type);
                }

                switch (message.type) {
                    case 'registered':
                        console.log('Registered as receiver');
                        receiverId = message.receiverId;
                        if (message.senderAvailable) {
                            overlayText.textContent = 'Sender available. Requesting stream...';
                            // Request an offer from the sender
                            sendSignal({ type: 'request-offer' });
                        } else {
                            overlayText.textContent = 'Waiting for sender to start streaming...';
                        }
                        break;

                    case 'sender-available':
                        overlayText.textContent = 'Sender started. Requesting stream...';
                        // Request an offer from the sender
                        sendSignal({ type: 'request-offer' });
                        break;

                    case 'sender-disconnected':
                        setDisconnectedState();
                        closePeerConnection();
                        break;

                    case 'offer':
                        console.log('Received offer');
                        await handleOffer(message.offer);
                        break;

                    case 'ice-candidate':
                        if (message.candidate) {
                            if (peerConnection && peerConnection.remoteDescription) {
                                try {
                                    await peerConnection.addIceCandidate(new RTCIceCandidate(message.candidate));
                                    console.log('Added ICE candidate');
                                } catch (err) {
                                    console.log('ICE candidate error (may be stale):', err.message);
                                }
                            } else {
                                // Queue candidate for later
                                console.log('Queuing ICE candidate');
                                pendingCandidates.push(message.candidate);
                            }
                        }
                        break;

                    case 'ptt-answer':
                        console.log('Received PTT answer');
                        if (peerConnection) {
                            try {
                                await peerConnection.setRemoteDescription(new RTCSessionDescription(message.answer));
                                console.log('PTT renegotiation complete');
                            } catch (err) {
                                console.error('PTT answer error:', err);
                            }
                        }
                        break;

                    case 'music-status':
                        console.log('Received music status:', message);
                        handleMusicStatus(message);
                        break;

                    case 'heartbeat':
                        // Server heartbeat - connection is alive
                        break;
                }
            };

            eventSource.onerror = (err) => {
                console.error('SSE error:', err);
                setDisconnectedState();
                eventSource.close();
                setTimeout(connectSSE, 3000);
            };
        }

        async function handleOffer(offer) {
            console.log('Handling offer...');
            closePeerConnection();

            // Clear any pending candidates from previous session
            pendingCandidates = [];

            peerConnection = new RTCPeerConnection(rtcConfig);
            console.log('Created peer connection');

            peerConnection.ontrack = (event) => {
                console.log('Received track:', event.track.kind, event.streams);

                // Always update srcObject with the latest stream
                remoteVideo.srcObject = event.streams[0];
                console.log('Set video srcObject, tracks in stream:', event.streams[0].getTracks().length);
                
                // Apply saved volume setting
                const savedVol = localStorage.getItem('receiver-volume');
                if (savedVol !== null) {
                    remoteVideo.volume = parseInt(savedVol) / 100;
                }

                // Show video as soon as we receive tracks
                if (event.track.kind === 'video') {
                    console.log('Video track received, showing video');
                    console.log('Video track enabled:', event.track.enabled);
                    console.log('Video track readyState:', event.track.readyState);
                    console.log('Video track muted:', event.track.muted);

                    setConnectedState(true);
                    info.textContent = 'Streaming';

                    // Monitor track for unmute (when data starts flowing)
                    event.track.onunmute = () => {
                        console.log('Video track unmuted - data flowing');
                        // Keep video element muted for autoplay, unmute after user interaction
                        remoteVideo.play().catch(err => {
                            console.log('Play error on track unmute:', err);
                            showPlayOverlay();
                        });
                    };

                    // Force play (muted for autoplay policy)
                    remoteVideo.muted = true;
                    remoteVideo.play().then(() => {
                        console.log('Video playing (muted), dimensions:', remoteVideo.videoWidth, 'x', remoteVideo.videoHeight);
                        // If user already interacted, unmute
                        if (userHasInteracted) {
                            remoteVideo.muted = false;
                            overlay.classList.add('hidden');
                        } else {
                            showPlayOverlay();
                        }
                    }).catch(err => {
                        console.error('Video play error:', err);
                        showPlayOverlay();
                    });

                    // Check dimensions after a delay
                    setTimeout(() => {
                        console.log('Video check - dimensions:', remoteVideo.videoWidth, 'x', remoteVideo.videoHeight);
                        console.log('Video check - paused:', remoteVideo.paused);
                        console.log('Video check - readyState:', remoteVideo.readyState);
                        console.log('Stream active:', remoteVideo.srcObject?.active);
                    }, 2000);
                }

                if (event.track.kind === 'audio') {
                    setupAudioAnalysis(event.streams[0]);
                }
            };

            peerConnection.onicecandidate = (event) => {
                if (event.candidate && eventSource) {
                    console.log('Sending ICE candidate');
                    sendSignal({
                        type: 'ice-candidate',
                        candidate: event.candidate
                    });
                }
            };

            peerConnection.oniceconnectionstatechange = () => {
                console.log('ICE connection state:', peerConnection.iceConnectionState);
                if (peerConnection.iceConnectionState === 'connected') {
                    console.log('ICE connected! Video should work now.');
                    // Keep muted for autoplay
                    remoteVideo.muted = !userHasInteracted;
                    remoteVideo.play().catch(e => {
                        console.log('Play on ICE connect:', e);
                        showPlayOverlay();
                    });
                }
                if (peerConnection.iceConnectionState === 'failed') {
                    console.error('ICE connection failed - trying restart');
                    peerConnection.restartIce();
                }
            };

            peerConnection.onicegatheringstatechange = () => {
                console.log('ICE gathering state:', peerConnection.iceGatheringState);
            };

            peerConnection.onconnectionstatechange = () => {
                console.log('Connection state:', peerConnection.connectionState);
                if (peerConnection.connectionState === 'connected') {
                    setConnectedState(true);
                    info.textContent = 'Streaming';
                } else if (peerConnection.connectionState === 'disconnected') {
                    info.textContent = 'Connection lost. Reconnecting...';
                    // Try to restart ICE
                    setTimeout(() => {
                        if (peerConnection && peerConnection.connectionState === 'disconnected') {
                            peerConnection.restartIce();
                        }
                    }, 2000);
                } else if (peerConnection.connectionState === 'failed') {
                    setDisconnectedState();
                    info.textContent = 'Connection failed. Requesting new stream...';
                    // Request a new offer from sender
                    setTimeout(() => {
                        if (eventSource) {
                            sendSignal({ type: 'request-offer' });
                        }
                    }, 2000);
                }
            };

            try {
                await peerConnection.setRemoteDescription(new RTCSessionDescription(offer));
                console.log('Set remote description');

                // Process any queued ICE candidates
                console.log('Processing', pendingCandidates.length, 'queued ICE candidates');
                for (const candidate of pendingCandidates) {
                    try {
                        await peerConnection.addIceCandidate(new RTCIceCandidate(candidate));
                    } catch (err) {
                        console.log('Queued ICE candidate error:', err.message);
                    }
                }
                pendingCandidates = [];

                const answer = await peerConnection.createAnswer();
                await peerConnection.setLocalDescription(answer);
                console.log('Created and set local answer');

                if (eventSource) {
                    sendSignal({
                        type: 'answer',
                        answer: peerConnection.localDescription
                    });
                    console.log('Sent answer to server');
                }
            } catch (err) {
                console.error('Error in handleOffer:', err);
            }
        }

        function closePeerConnection() {
            if (peerConnection) {
                peerConnection.close();
                peerConnection = null;
            }
            if (audioContext) {
                audioContext.close();
                audioContext = null;
                analyser = null;
            }
            audioStream = null;
        }

        function setupAudioAnalysis(stream) {
            audioStream = stream;
            tryStartAudioAnalysis();
        }

        async function tryStartAudioAnalysis() {
            if (!audioStream) return;

            try {
                // Create or resume AudioContext
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }

                // Resume if suspended (browser autoplay policy)
                if (audioContext.state === 'suspended') {
                    console.log('AudioContext suspended, will resume on user interaction');
                    return;
                }

                analyser = audioContext.createAnalyser();
                const source = audioContext.createMediaStreamSource(audioStream);
                source.connect(analyser);
                analyser.fftSize = 256;
                analyser.smoothingTimeConstant = 0.3;

                const dataArray = new Uint8Array(analyser.frequencyBinCount);
                console.log('Audio analysis started');

                function updateAudioLevel() {
                    if (!analyser) return;

                    analyser.getByteFrequencyData(dataArray);

                    // Calculate RMS (root mean square) for better loudness detection
                    let sum = 0;
                    for (let i = 0; i < dataArray.length; i++) {
                        sum += dataArray[i] * dataArray[i];
                    }
                    const rms = Math.sqrt(sum / dataArray.length);
                    const percentage = Math.min(100, (rms / 128) * 100);

                    audioLevel.style.width = percentage + '%';

                    // Check for loud sounds based on sensitivity
                    // Sensitivity 10 = threshold 90 (hard to trigger)
                    // Sensitivity 100 = threshold 0 (very easy to trigger)
                    const threshold = 100 - parseInt(sensitivitySlider.value);
                    if (percentage > threshold && isConnected) {
                        console.log('Loud sound detected! Level:', percentage.toFixed(1), 'Threshold:', threshold);
                        triggerLoudSoundAlert();
                    }

                    requestAnimationFrame(updateAudioLevel);
                }

                updateAudioLevel();
            } catch (err) {
                console.error('Audio analysis error:', err);
            }
        }

        // Resume AudioContext on any user interaction
        document.addEventListener('click', async () => {
            if (audioContext && audioContext.state === 'suspended') {
                await audioContext.resume();
                console.log('AudioContext resumed');
                tryStartAudioAnalysis();
            }
        }, { once: false });

        document.addEventListener('touchstart', async () => {
            if (audioContext && audioContext.state === 'suspended') {
                await audioContext.resume();
                console.log('AudioContext resumed');
                tryStartAudioAnalysis();
            }
        }, { once: false });

        // Volume control
        volumeSlider.addEventListener('input', () => {
            const value = volumeSlider.value / 100;
            remoteVideo.volume = value;
            remoteVideo.muted = false; // Unmute when adjusting volume
            volumeValue.textContent = volumeSlider.value + '%';
            overlay.classList.add('hidden'); // Hide unmute prompt if shown
            // Save to localStorage
            localStorage.setItem('receiver-volume', volumeSlider.value);
        });

        // Sensitivity control
        const thresholdMarker = document.getElementById('thresholdMarker');

        function updateThresholdMarker() {
            // threshold = 100 - sensitivity
            // so marker position should be at (100 - sensitivity)%
            const threshold = 100 - parseInt(sensitivitySlider.value);
            thresholdMarker.style.left = threshold + '%';
            sensitivityValue.textContent = sensitivitySlider.value;
        }

        sensitivitySlider.addEventListener('input', () => {
            updateThresholdMarker();
            // Save to localStorage
            localStorage.setItem('receiver-sensitivity', sensitivitySlider.value);
        });
        updateThresholdMarker(); // Set initial position

        // Fullscreen
        fullscreenBtn.addEventListener('click', () => {
            if (document.fullscreenElement) {
                document.exitFullscreen();
            } else {
                document.documentElement.requestFullscreen();
            }
        });

        // Handle unmuting (video starts muted for autoplay policy)
        function showPlayOverlay(message) {
            overlayText.textContent = message || 'Tap to play';
            overlay.classList.remove('hidden');
            console.log('Showing overlay:', message);
        }
        
        function hideOverlay() {
            overlay.classList.add('hidden');
        }

        // Handle video play (required for autoplay on mobile)
        function tryPlayVideo() {
            if (!remoteVideo.srcObject) return;
            
            // First try: play with sound (might work if user already interacted)
            remoteVideo.muted = false;
            remoteVideo.play().then(() => {
                console.log('Video playing with sound!');
                hideOverlay();
            }).catch(err => {
                console.log('Play with sound failed, trying muted:', err.message);
                
                // Second try: play muted
                remoteVideo.muted = true;
                remoteVideo.play().then(() => {
                    console.log('Video playing muted');
                    // Show overlay to let user enable sound
                    showPlayOverlay('Tap to enable sound');
                }).catch(err2 => {
                    console.log('Even muted play failed:', err2.message);
                    // Need user interaction to play at all
                    showPlayOverlay('Tap to play');
                });
            });
        }
        
        remoteVideo.addEventListener('loadedmetadata', tryPlayVideo);
        
        // Handle user interaction - enable autoplay and unmute
        function handleUserInteraction() {
            if (userHasInteracted) return;
            userHasInteracted = true;
            console.log('User interaction detected');
            
            // Try to play and unmute
            if (remoteVideo.srcObject) {
                remoteVideo.muted = false;
                remoteVideo.play().then(() => {
                    console.log('Video playing after interaction');
                    overlay.classList.add('hidden');
                }).catch(e => console.log('Play after interaction failed:', e));
            }
        }
        
        // Listen for any user interaction
        ['click', 'touchstart', 'touchend', 'keydown'].forEach(event => {
            document.addEventListener(event, handleUserInteraction, { once: false, passive: true });
        });
        
        // Also handle overlay click specifically
        overlay.addEventListener('click', () => {
            handleUserInteraction();
            if (remoteVideo.srcObject) {
                remoteVideo.muted = false;
                remoteVideo.play().then(() => {
                    overlay.classList.add('hidden');
                }).catch(e => console.log('Overlay play error:', e));
            }
        });

        // Push-to-talk functionality
        async function startPTT() {
            if (pttActive) {
                console.log('PTT: Already active');
                return;
            }
            if (!peerConnection || !isConnected) {
                console.log('PTT: No peer connection or not connected');
                return;
            }

            pttActive = true;

            try {
                pttBtn.classList.add('active');
                pttLabel.textContent = 'Speaking...';
                
                // Audio ducking - lower baby audio to prevent echo
                preDuckVolume = remoteVideo.volume;
                remoteVideo.volume = Math.min(remoteVideo.volume, DUCKING_VOLUME);
                console.log('PTT: Ducked audio from', preDuckVolume, 'to', remoteVideo.volume);

                // Immediately notify sender that PTT is starting
                if (eventSource) {
                    sendSignal({ type: 'ptt-start' });
                    console.log('PTT: Sent start notification');
                }

                // Get microphone access
                console.log('PTT: Requesting microphone...');
                pttStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });
                console.log('PTT: Got microphone');

                // Add audio track to peer connection
                const audioTrack = pttStream.getAudioTracks()[0];
                pttSender = peerConnection.addTrack(audioTrack, pttStream);
                console.log('PTT: Added track to peer connection');

                // Renegotiate connection
                console.log('PTT: Creating offer, signaling state:', peerConnection.signalingState);
                const offer = await peerConnection.createOffer();
                await peerConnection.setLocalDescription(offer);
                console.log('PTT: Offer created');

                if (eventSource) {
                    const message = {
                        type: 'ptt-offer',
                        offer: peerConnection.localDescription
                    };
                    console.log('PTT: Sending to server:', message.type);
                    sendSignal(message);
                    console.log('PTT: Sent to server');
                } else {
                    console.error('PTT: SSE not connected');
                }

                console.log('PTT: Started, waiting for answer...');
            } catch (err) {
                console.error('PTT error:', err);
                pttLabel.textContent = 'Mic access denied';
                stopPTT();
            }
        }

        let pttActive = false;

        function stopPTT() {
            if (!pttActive) return; // Prevent multiple calls
            pttActive = false;

            console.log('PTT: Stopping...');
            pttBtn.classList.remove('active');
            pttLabel.textContent = 'Hold to talk to baby';
            
            // Restore audio volume (un-duck)
            if (preDuckVolume !== null) {
                remoteVideo.volume = preDuckVolume;
                console.log('PTT: Restored audio to', preDuckVolume);
                preDuckVolume = null;
            }

            // Notify sender that PTT has stopped
            if (eventSource) {
                sendSignal({ type: 'ptt-stop' });
                console.log('PTT: Sent stop notification');
            }

            // Stop microphone
            if (pttStream) {
                pttStream.getTracks().forEach(track => track.stop());
                pttStream = null;
                console.log('PTT: Microphone stopped');
            }

            // Remove track from peer connection
            if (pttSender && peerConnection) {
                try {
                    peerConnection.removeTrack(pttSender);
                    console.log('PTT: Track removed from peer connection');
                } catch (e) {
                    console.log('PTT: Could not remove track:', e);
                }
                pttSender = null;
            }

            console.log('PTT: Stopped');
        }

        // PTT button events (mouse)
        pttBtn.addEventListener('mousedown', (e) => {
            e.preventDefault();
            startPTT();
        });

        pttBtn.addEventListener('mouseup', stopPTT);
        pttBtn.addEventListener('mouseleave', stopPTT);

        // PTT button events (touch)
        pttBtn.addEventListener('touchstart', (e) => {
            e.preventDefault();
            startPTT();
        });

        pttBtn.addEventListener('touchend', (e) => {
            e.preventDefault();
            stopPTT();
        });

        pttBtn.addEventListener('touchcancel', stopPTT);

        // Enable PTT when connected
        function updatePTTState() {
            pttBtn.disabled = !isConnected || !peerConnection;
        }

        // Debug video events
        remoteVideo.addEventListener('loadeddata', () => {
            console.log('Video loadeddata - dimensions:', remoteVideo.videoWidth, 'x', remoteVideo.videoHeight);
        });

        remoteVideo.addEventListener('playing', () => {
            console.log('Video is now playing');
        });

        remoteVideo.addEventListener('waiting', () => {
            console.log('Video is waiting for data');
        });

        remoteVideo.addEventListener('stalled', () => {
            console.log('Video stalled');
        });

        // Initialize - connect SSE
        connectSSE();
    </script>
</body>
</html>